数据分析和模型训练

数据分析

我们首先对人工标注的300条样例进行了数据分析，主要用的是文本长度分析和POS词性分析。这是关于这300条样例的文本长度总体数据，吴梓扬同学采用单因素方差分析观察了文本标题长度和文本长度与BWS情感强度之间的关联性，分析结果如下，其影响较为显著。然后是关于词性的分析，这是吴同学统计的真假新闻中的词性直方分布，下图是真假新闻词性分布图百分比相减的结果，可以看出a，ns， vn等词性有着较明显的变化。这是余恒宇所做的词云图，比较清晰直观。刘方圆同学还对数据集中的其他统计学特征，如emoji数量、标题数量以及文本可读性、标题和文本的余弦相似度做了分析，其统计结果如下所示。

模型训练

fake news检测实质上是一个文本分类问题，根据Rubin et al在2015年所说，可以根据以下定义来细分三类：1.严重捏造 2. 大规模恶作剧 3.幽默性质的作假。在本次任务中，我们所做的比较简单，仅对文本的真或假进行分类，实际上就是一个二分类的问题。

我们一共训练了七种模型，包括三种机器学习模型和四种深度学习模型。在经过五折或十折检验后MultinomialNB模型在使用默认参数的情况下的准确率基本都在60%-65%之间。

然后是SVM模型，模型性能准确度和NB模型相比没有太大出入，吴同学分别对Linear、Poly和Rbf三种核函数进行了对比，总体结果如图所示，性能上Linear略优于Rbf略优于Poly。

然后是LR模型，以文本分词后编码作为输入所训练得到的模型性能和NB也依然没有差别，经过五折和十折检验后所得到的准确度依然是在60%-65%之间。

深度学习模型中，主要训练了LSTM模型，TextCNN模型、BERT模型以及RoBERTa模型。这是余同学所跑的所有模型的总体性能。到了这里我们所训练的模型性能开始有了一定的差异。但总体上性能是RoBERTa优于BERT优于LSTM优于TextCNN。在余恒宇同学所跑的所有模型中呢，BertDPCNN模型的性能是最高的，其结果展示如下。

此外，余恒宇同学还跑了大模型，使用Baicuan7B基座模型+qlora 4 bit量化微调，其中提示词模板如下：    这边是微调之后的统计回答。

在训练模型阶段，刘同学还展开了一些其他的实验：

首先是不同特征集和模型组合对预测结果的影响。特征集分别使用了手工提取的特征、词项量和句向量，手工特征提取包括文本的统计学特征、词性计数、语言学特征和LIWC，词项量提取是用bert模型得到文本中每个token的index，句向量是将文本（不含标签）数据输入roberta模型，得到最后一个pooler层的输出。将此作为模型的输入。其实验结果如下：

然后是对于数据集单领域内的训练和测试，其测试结果如下：

最后是交叉领域上模型的训练和预测。这里分为三组小的实验。一是以单一领域为训练集对其他所有领域数据进行测试。二是以单一领域为训练集对其他单个领域进行测试。三是以其他领域数据为训练集对单个领域数据进行测试。其最终结果呈现如下。

