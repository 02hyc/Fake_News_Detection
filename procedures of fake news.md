如果要从零进行假新闻检测的话，要进行以下几个步骤：假新闻的定义、数据集的制作、对数据集的特征进行提取、训练模型、评估模型性能、进行分析实验以及确定该模型的实际应用场景。

首先是假新闻的定义。首先假新闻，它的文本性质一定是新闻文章，是带有明显的错误引导性质、为误导读者而产生的虚假新闻文本信息，根据程度可以分为三个层级：严重的歪曲捏造（serious fabrications）、恶作剧（hoaxes）和讽刺（satires）。要区分那些无意误导读者或不太可能被误认为事实的新闻，这些不能归作假新闻的范畴。

然后是数据集的制作，论文中提到的Liar、CREDBANK、FakeNewsAMT等数据集各有优劣，但主要问题还是这些数据集应该都是基于英文文本的。如果要对中文文本进行fake news检测，可能需要自己去制作数据集。可以从互联网、新闻网站（扬子晚报等地方性报纸的官方网站或腾讯新闻、网易新闻等站点）或新浪微博等社交媒体上收集数据，数据需要具有一定规模，需要注意搜集新闻的发布者、文本内容、标题、来源等信息，同时要注意所搜集数据的领域覆盖要广。然后需要对数据进行标注，要基于之前对于假新闻的定义对数据进行人工标注，或者使用半自动方法标注数据。然后需要对数据集进行分割，基于数据集的随机性分为训练集、验证集和测试集。

之后是对于特征的提取。使用Ngrams方法，提取文本中关于标点符号、心理学特征单词（基于LIWC）、可读性和文本语法等特征。还要提取基于用户的，关于用户信息（注册时间、关注和粉丝数量、发帖数量）的特征，关于文本内容中所表达的公众反应、立场、可信度的特征和用户在社交媒体上的兴趣、关系网络。

然后是模型的训练。可以使用Hugging Face的Transformers库加载BERT模型，然后根据fake news任务要求修改相应的参数。要用不同的特征集组合进行实验，基于写作风格(标点符号、可读性、语法)或基于writer's internal processes(心理学特征单词)进行实验。

可以将fake news检测视作一个文本分类任务，依据此而定义Precision、Recall、F1和Accuracy指标，评估模型的预测性能。依据BERT模型的输出结果进行文本的分类，依据模型性能进行参数调整，直到其能较好的完成预测任务。

然后可以进行分析实验，比如减少BERT层数观察模型的性能变化，或者对数据进行随机删除、替换、交换等操作，进行数据增强实验。

最后，这个训练好的模型可以对社交媒体发布的新闻进行检测，帮助用户辨别新闻的真假，还可以帮助社交媒体对用户的发布内容进行审核，过滤掉潜在的假新闻消息，对网络上的假新闻进行干预。